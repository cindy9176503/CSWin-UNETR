{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfPPQ6ztJhv4"
   },
   "source": [
    "# Get Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/Workspace/TeethSeg/exps\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBIoe_tHTQgV",
    "outputId": "94d68c78-d658-43c9-845b-f3c35b3b817f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install SimpleITK\n",
    "# !pip install cython\n",
    "\n",
    "# !conda install pytorch\n",
    "\n",
    "# Install pycocotools, \n",
    "# the version by default in Colab\n",
    "# has a bug fixed in https://github.com/cocodataset/cocoapi/pull/354\n",
    "# !pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RoE48VcBNrmK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.function_base import append\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/nfs/Workspace/dataset/teeth/data50'\n",
    "\n",
    "img_dir = os.path.join(root_dir, 'image')\n",
    "mask_dir = os.path.join(root_dir, 'label')\n",
    "\n",
    "save_dir = os.path.join(root_dir, 'center')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"/nfs/Workspace/dataset/teeth/data50/label/1001012179_20180110.nii.gz\" does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1517284/2841429568.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1001012179_20180110'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nii.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetArrayFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlbl_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/TeethSeg/lib/python3.10/site-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetFileNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/TeethSeg/lib/python3.10/site-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8434\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mitk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mConvertPixelBuffer\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mconvert\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpixels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8437\u001b[0m         \"\"\"\n\u001b[0;32m-> 8438\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:97:\nsitk::ERROR: The file \"/nfs/Workspace/dataset/teeth/data50/label/1001012179_20180110.nii.gz\" does not exist."
     ]
    }
   ],
   "source": [
    "pid = '1001012179_20180110'\n",
    "masks = sitk.ReadImage(os.path.join(mask_dir, pid+'.nii.gz'))\n",
    "masks = sitk.GetArrayFromImage(masks).astype(np.uint8)\n",
    "plt.imshow(masks[120,:,:])\n",
    "lbl_list = np.unique(masks)\n",
    "print(len(lbl_list))\n",
    "print(lbl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('ToothDataset/cbcts/cswin_unter/data50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_mask = np.zeros_like(masks)\n",
    "tmp_mask[masks == lbl_list[2]] = lbl_list[2]\n",
    "print(np.unique(tmp_mask))\n",
    "plt.imshow(tmp_mask[130,:,:])\n",
    "\n",
    "out = sitk.GetImageFromArray(tmp_mask)\n",
    "out_name = '{}/{}_tmp_mask1.nii.gz'.format(save_path, pid)\n",
    "sitk.WriteImage(out, out_name)\n",
    "print('! save ', out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((8,8),np.uint8)\n",
    "fg = cv.erode(tmp_mask, kernel, iterations=1)\n",
    "print(np.unique(fg))\n",
    "# out = sitk.GetImageFromArray(fg)\n",
    "# out_name = '{}/{}_tmp_mask1_erode.nii.gz'.format(save_path, pid)\n",
    "# sitk.WriteImage(out, out_name)\n",
    "# print('! save ', out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fg[:,:,120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egde = cv.subtract(tmp_mask, fg)\n",
    "print(np.unique(egde))\n",
    "# plt.figure(dpi=200)\n",
    "# plt.imshow(egde[:,:, 120], cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# out = sitk.GetImageFromArray(egde)\n",
    "# out_name = '{}/{}_tmp_mask1_edge.nii.gz'.format(save_path, pid)\n",
    "# sitk.WriteImage(out, out_name)\n",
    "# print('! save ', out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "# mask = masks.copy()\n",
    "\n",
    "# plt.figure(dpi=200)\n",
    "# plt.subplot(141)\n",
    "# plt.imshow(mask[120,:,:])\n",
    "\n",
    "# plt.subplot(142)\n",
    "# dil = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel, iterations = 1)\n",
    "# plt.imshow(dil[120,:,:])\n",
    "\n",
    "# plt.subplot(143)\n",
    "# dil2 = cv.dilate(mask, kernel, iterations=2)\n",
    "# plt.imshow(dil2[120,:,:])\n",
    "\n",
    "# plt.subplot(144)\n",
    "# ed = cv.subtract(dil2, dil)\n",
    "# plt.imshow(ed[120,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "['1000813648_20180116.nii.gz', '1000889125_20171009.nii.gz', '1000889125_20171016.nii.gz', '1000889125_20180109.nii.gz', '1000889125_20180521.nii.gz', '1000889125_20181106.nii.gz', '1000889125_20190408.nii.gz', '1000889125_20191101.nii.gz', '1000889125_20200421.nii.gz', '1000915187_20180115.nii.gz', '1000915187_20191217.nii.gz', '1000966359_20180113.nii.gz', '1000971031_20180112.nii.gz', '1000983254_20180109.nii.gz', '1000983254_20180904.nii.gz', '1000995722_20180112.nii.gz', '1001009635_20180116.nii.gz', '1001012179_20180116.nii.gz', '1001020384_20180114.nii.gz', '1001022839_20180110.nii.gz', '1001022839_20180225.nii.gz', '1001028863_20180115.nii.gz', '1001068663_20180116.nii.gz', '1001111103_20180114.nii.gz', '1001127112_20180109.nii.gz', '1001133637_20180110.nii.gz', '1001142392_20180110.nii.gz', '1001142392_20180116.nii.gz', '1001142392_20180511.nii.gz', '1001152328_20150714.nii.gz', '1001152328_20180112.nii.gz', '1001152328_20180306.nii.gz', '1001152328_20180910.nii.gz', '1001162439_20140520.nii.gz', '1001162439_20150708.nii.gz', '1001162439_20180110.nii.gz', '1001162439_20200910.nii.gz', '1001172283_20180110.nii.gz', '1001172283_20190622.nii.gz', '1001173165_20171205.nii.gz', '1001173165_20180115.nii.gz', '1001173165_20180521.nii.gz', '1001213121_20180115.nii.gz', '1001218388_20161024.nii.gz', '1001218388_20171102.nii.gz', '1001218388_20180109.nii.gz', '1001223657_20180112.nii.gz', '1001224969_20180330.nii.gz', '1001232054_20180109.nii.gz', '1001247962_20180115.nii.gz', '1001250407_20180115.nii.gz', '1001250407_20190306.nii.gz', '1001261667_20180109.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "mask_names = list(sorted([_ for _ in os.listdir(mask_dir) if _.endswith('.nii.gz')]))\n",
    "print(len(mask_names))\n",
    "print(mask_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(mask_names[:]):\n",
    "    data_path = os.path.join(mask_dir, data)\n",
    "\n",
    "    data_nii = sitk.ReadImage(data_path)\n",
    "    masks = sitk.GetArrayFromImage(data_nii).astype(np.uint8)\n",
    "\n",
    "    lbl_list = np.unique(masks)\n",
    "    center = np.zeros_like(masks)\n",
    "    kernel01 = np.ones((3,3),np.uint8)\n",
    "    kernel02 = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    for lbl in lbl_list[1:]:\n",
    "        tmp_mask = np.zeros_like(masks)\n",
    "        tmp_mask[masks == lbl] = lbl\n",
    "        if np.any(tmp_mask):\n",
    "            fg = cv.erode(tmp_mask, kernel01, iterations=3)\n",
    "            center[fg == lbl] = lbl\n",
    "    \n",
    "    center_img = sitk.GetImageFromArray(center)\n",
    "    \n",
    "    center_img.SetOrigin(data_nii.GetOrigin())\n",
    "    center_img.SetDirection(data_nii.GetDirection())\n",
    "    center_img.SetSpacing(data_nii.GetSpacing())\n",
    "\n",
    "    save_path = os.path.join(save_dir, data)\n",
    "    sitk.WriteImage(center_img, save_path)\n",
    "    \n",
    "    # print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tqdm(mask_names[50:]):\n",
    "    data_path = os.path.join(mask_dir, data)\n",
    "    # print(data_path)\n",
    "    data_nii = sitk.ReadImage(data_path)\n",
    "    masks = sitk.GetArrayFromImage(data_nii).astype(np.uint8)\n",
    "\n",
    "    lbl_list = np.unique(masks)\n",
    "    center = np.zeros_like(masks)\n",
    "    kernel01 = np.ones((3,3),np.uint8)\n",
    "    kernel02 = np.ones((3,3),np.uint8)\n",
    "    \n",
    "    for lbl in lbl_list[1:]:\n",
    "        tmp_mask = np.zeros_like(masks)\n",
    "        tmp_mask[masks == lbl] = lbl\n",
    "        if np.any(tmp_mask):\n",
    "            fg = cv.erode(tmp_mask, kernel01, iterations=3)\n",
    "            # tmp_edge = cv.subtract(tmp_mask, fg)\n",
    "            # tmp_edge = cv.dilate(tmp_edge, kernel02, iterations=1)\n",
    "            # tmp_edge = cv.morphologyEx(tmp_edge, cv.MORPH_CLOSE, kernel02, iterations = 1)\n",
    "            center[fg == lbl] = lbl\n",
    "    \n",
    "    center_img = sitk.GetImageFromArray(center)\n",
    "    \n",
    "#     plt.figure(dpi=200)\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(edgemap[103,:,:], cmap='gray')\n",
    "#     # plt.savefig('edge.jpg')\n",
    "    \n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(masks[140,:,:], cmap='gray')\n",
    "#     # plt.savefig('masks.jpg')\n",
    "    \n",
    "    center_img.SetOrigin(data_nii.GetOrigin())\n",
    "    center_img.SetDirection(data_nii.GetDirection())\n",
    "    center_img.SetSpacing(data_nii.GetSpacing())\n",
    "\n",
    "    save_path = os.path.join(save_dir, data)\n",
    "    sitk.WriteImage(center_img, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in tqdm(mask_names[:1]):\n",
    "    data_path = os.path.join(mask_dir, data)\n",
    "    # print(data_path)\n",
    "    data_nii = sitk.ReadImage(data_path)\n",
    "    masks = sitk.GetArrayFromImage(data_nii).astype(np.uint8)\n",
    "    masks[masks>0] = 1\n",
    "\n",
    "    edge_arr = np.zeros_like(masks)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    for i in range(edge_arr.shape[0]):\n",
    "        edge_arr[i] = cv.Canny(masks[i], 1, 2)\n",
    "    \n",
    "    edge_arr = cv.morphologyEx(edge_arr, cv.MORPH_CLOSE, kernel, iterations = 4)\n",
    "    edge_arr = cv.dilate(edge_arr, kernel, iterations=2)\n",
    "    \n",
    "    edge_img = sitk.GetImageFromArray(edge_arr)\n",
    "    \n",
    "    plt.figure(dpi=200)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(edge_arr[123,:,:], cmap='gray')\n",
    "    plt.savefig('edge.jpg')\n",
    "    \n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(masks[140,:,:], cmap='gray')\n",
    "#     plt.savefig('masks.jpg')\n",
    "    \n",
    "    edge_img.SetOrigin(data_nii.GetOrigin())\n",
    "    edge_img.SetDirection(data_nii.GetDirection())\n",
    "    edge_img.SetSpacing(data_nii.GetSpacing())\n",
    "\n",
    "    save_path = os.path.join(save_dir, data)\n",
    "    sitk.WriteImage(edge_img, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t4TBwhHTdkd"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "# download the Penn-Fudan dataset\n",
    "# wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip .\n",
    "# extract it in the current folder\n",
    "# unzip PennFudanPed.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfwuU-jI3j93"
   },
   "source": [
    "Let's have a look at the dataset and how it is layed down.\n",
    "\n",
    "The data is structured as follows\n",
    "```\n",
    "PennFudanPed/\n",
    "  PedMasks/\n",
    "    FudanPed00001_mask.png\n",
    "    FudanPed00002_mask.png\n",
    "    FudanPed00003_mask.png\n",
    "    FudanPed00004_mask.png\n",
    "    ...\n",
    "  PNGImages/\n",
    "    FudanPed00001.png\n",
    "    FudanPed00002.png\n",
    "    FudanPed00003.png\n",
    "    FudanPed00004.png\n",
    "```\n",
    "\n",
    "Here is one example of an image in the dataset, with its corresponding instance segmentation mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9Ee5NV54Dmj"
   },
   "source": [
    "So each image has a corresponding segmentation mask, where each color correspond to a different instance. Let's write a `torch.utils.data.Dataset` class for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    # global dataset_mask_path\n",
    "\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list([_ for _ in os.listdir(os.path.join(root,'PNGImages')) if _.endswith('.png')])\n",
    "        self.masks = list(sorted([_ for _ in os.listdir(os.path.join(root,'GrayMasks')) if _.endswith('.png')]))\n",
    "        self.imgs = sorted(self.imgs, key=lambda s:nfs.get_nums(s))\n",
    "        self.masks = sorted(self.masks, key=lambda s:nfs.get_nums(s))\n",
    "        \n",
    "    def __getitem__(self, idx):       \n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        graymask_path = os.path.join(self.root, \"GrayMasks\", self.masks[idx])\n",
    "        # print(img_path)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask = Image.open(graymask_path)        \n",
    "        mask = np.array(mask)\n",
    "        \n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # idx_list = []\n",
    "        # idx_list = [i for i, _ in enumerate(obj_ids, 1)]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            \n",
    "            if xmin < xmax and ymin < ymax:\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        if(boxes.shape[0]==0):\n",
    "            area = torch.tensor([0])\n",
    "        else:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target[\"img_path\"] = img_path\n",
    "        target[\"graymask_path\"] = graymask_path\n",
    "        \n",
    "        # use PennFudanDataset('ToothDataset/train', get_transform(train=False))\n",
    "        #                                           -----------------------------\n",
    "        # let type(img) : <class 'PIL.Image.Image'> -> <class 'torch.Tensor'>\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EdgeMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PennFudanDataset(torch.utils.data.Dataset):\n",
    "    # global dataset_mask_path\n",
    "\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list([_ for _ in os.listdir(os.path.join(root,'PNGImages')) if _.endswith('.png')])\n",
    "        self.masks = list(sorted([_ for _ in os.listdir(os.path.join(root,'EdgeMaps')) if _.endswith('.png')]))\n",
    "        self.imgs = sorted(self.imgs, key=lambda s:nfs.get_nums(s))\n",
    "        self.masks = sorted(self.masks, key=lambda s:nfs.get_nums(s))\n",
    "        \n",
    "    def __getitem__(self, idx):       \n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, \"PNGImages\", self.imgs[idx])\n",
    "        graymask_path = os.path.join(self.root, \"EdgeMaps\", self.masks[idx])\n",
    "        # print(img_path)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask = Image.open(graymask_path)        \n",
    "        mask = np.array(mask)\n",
    "        \n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # idx_list = []\n",
    "        # idx_list = [i for i, _ in enumerate(obj_ids, 1)]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            \n",
    "            if xmin < xmax and ymin < ymax:\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "\n",
    "        if(boxes.shape[0]==0):\n",
    "            area = torch.tensor([0])\n",
    "        else:\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        target[\"img_path\"] = img_path\n",
    "        target[\"graymask_path\"] = graymask_path\n",
    "        \n",
    "        # use PennFudanDataset('ToothDataset/train', get_transform(train=False))\n",
    "        #                                           -----------------------------\n",
    "        # let type(img) : <class 'PIL.Image.Image'> -> <class 'torch.Tensor'>\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "            \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6f3ZOTJ4Km9"
   },
   "source": [
    "That's all for the dataset. Let's see how the outputs are structured for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWOhcsir9Ahx"
   },
   "source": [
    "So we can see that by default, the dataset returns a `PIL.Image` and a dictionary\n",
    "containing several fields, including `boxes`, `labels` and `masks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PennFudanDataset('ToothDataset/train')\n",
    "# dataset = PennFudanDataset('ToothDataset/test/1001152328_20150714')\n",
    "img_slices, target_slices = dataset[150]\n",
    "masks = target_slices['masks']\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_slices, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(masks[2,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(im, boxes):\n",
    "    im = Image.fromarray(np.uint8(im))\n",
    "    image = im.copy()\n",
    "\n",
    "    draw = ImageDraw.Draw(image) #實例化一個對象\n",
    "    rows = boxes.shape[0]\n",
    "    cols = boxes.shape[1]\n",
    "\n",
    "    for i in range(rows):\n",
    "        # [xmin, ymin, xmax, ymax]\n",
    "        xmin = boxes[i][0].item()\n",
    "        ymin = boxes[i][1].item()\n",
    "        xmax = boxes[i][2].item()\n",
    "        ymax = boxes[i][3].item()\n",
    "\n",
    "        # draw.line((100,200, 150, 300), fill=128, width=3)\n",
    "        draw.line((xmin, ymin, xmax, ymin), fill=\"red\", width=1)  #line start and end coord, line width\n",
    "        draw.line((xmax, ymin, xmax, ymax), fill=\"red\", width=1)\n",
    "        draw.line((xmax, ymax, xmin, ymax), fill=\"red\", width=1)\n",
    "        draw.line((xmin, ymax, xmin, ymin), fill=\"red\", width=1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw boxes\n",
    "dataset_idx = 120\n",
    "\n",
    "test_data = dataset[dataset_idx][1]\n",
    "image_id = test_data['image_id'].item()\n",
    "\n",
    "img_path = test_data['img_path']\n",
    "mask_path = test_data['graymask_path']\n",
    "boxes = test_data['boxes']\n",
    "\n",
    "print('img_path = ', img_path)\n",
    "print('mask_path = ', mask_path)\n",
    "\n",
    "masks = sitk.ReadImage(mask_path)\n",
    "masks = sitk.LabelToRGB(masks)\n",
    "masks = sitk.GetArrayViewFromImage(masks).astype(np.int8)\n",
    "\n",
    "draw = drawLine(masks, boxes)\n",
    "draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjNHjVMOyYlH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "      \n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True) #True False\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYDb7PBw55b-"
   },
   "outputs": [],
   "source": [
    "# %%shell\n",
    "\n",
    "# # Download TorchVision repo to use some files from\n",
    "# # references/detection\n",
    "# git clone https://github.com/pytorch/vision.git\n",
    "# cd vision\n",
    "# git checkout -f v0.8.2\n",
    "\n",
    "# cp references/detection/utils.py ../\n",
    "# cp references/detection/transforms.py ../\n",
    "# cp references/detection/coco_eval.py ../\n",
    "# cp references/detection/engine.py ../\n",
    "# cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2u9e_pdv54nG"
   },
   "source": [
    "\n",
    "\n",
    "Let's write some helper functions for data augmentation / transformation, which leverages the functions in `refereces/detection` that we have just copied:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l79ivkwKy357",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # during training, randomly flip the training images\n",
    "        # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovjC81FZfWat"
   },
   "source": [
    "#### Testing forward() method \n",
    "\n",
    "Before iterating over the dataset, it’s good to see what the model expects during training and inference time on sample data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-NFR--2fXV3"
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False) #True\n",
    "# dataset = PennFudanDataset('ToothDataset', get_transform(train=False)) #True\n",
    "# data_loader = torch.utils.data.DataLoader(\n",
    "#     dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "#     collate_fn=utils.collate_fn\n",
    "# )\n",
    "# # For Training\n",
    "# images,targets = next(iter(data_loader))\n",
    "# images = list(image for image in images)\n",
    "# targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "# output = model(images,targets)   # Returns losses and detections\n",
    "# # For inference\n",
    "# model.eval()\n",
    "# x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "# predictions = model(x)           # Returns predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzCLqiZk-sjf"
   },
   "source": [
    "#### Note that we do not need to add a mean/std normalization nor image rescaling in the data transforms, as those are handled internally by the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YFJGJxk6XEs"
   },
   "source": [
    "### Putting everything together\n",
    "\n",
    "We now have the dataset class, the models and the data transforms. Let's instantiate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = PennFudanDataset('ToothDataset/train', get_transform(train=True)) #True\n",
    "eval_dataset = PennFudanDataset('ToothDataset/train', get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50]) #indices[:-50]\n",
    "eval_dataset = torch.utils.data.Subset(eval_dataset, indices[-50:]) #indices[-50:]\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "eval_data_loader = torch.utils.data.DataLoader(\n",
    "    eval_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_loader))\n",
    "print(len(eval_data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5yvZUprj4ZN",
    "tags": []
   },
   "source": [
    "### Now let's instantiate the model and the optimizerdataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeRJNcPt8DTH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instance seg\n",
    "pretrained_model_pth = os.path.join(\"/home/cg/maskrcnn2d/ToothDataset\", \"best_metric_model_SGD_360.pth\")\n",
    "\n",
    "# edge maps\n",
    "# pretrained_model_pth = os.path.join(\"/home/cg/maskrcnn2d/ToothDataset\", \"best_metric_model_edgemaps.pth\")\n",
    "\n",
    "print(pretrained_model_pth)\n",
    "# pretrained_model_pth = os.path.join(\"/content/drive/Shareddrives/Tooth/Pytorch_MaskRCNN/ToothDataset\", \"best_metric_model_usePreTrain.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.001) #lr=0.0001 0000025 -> Bad result\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "a2be8afdf34b41d4899044bd60a1578a",
      "c70f2759a56943e4afbe9b16e8cb674d",
      "aad68761f4104facab4f5ebcaa5757ec",
      "79e163d7476a4ab0a1ed8cf4ced63bc2",
      "fdf4af52c36044efb0856358f20bc9c3",
      "d950bd6f7ee645738dee16375d152398",
      "f5b9743788664542a057cf35ac35118f",
      "045816cebf604ed1b753a6346d76ba8a",
      "0edaade0427d4be48aaf90d21c320f77",
      "0fca824b90ee4c0581aa00cd5494f37f",
      "b1f9df056a0549f1b855975b3a764031"
     ]
    },
    "id": "zoenkCj18C4h",
    "outputId": "1dd73f6f-e09f-47e9-adab-3ff10c24d2d7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "# move model to the right device\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.SGD(params, lr=0.0001, momentum=0.9, weight_decay=0.0005)\n",
    "# optimizer = torch.optim.Adam(params, lr=0.0001) #lr=0.0001 0000025\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "checkpoint = torch.load(pretrained_model_pth)      \n",
    "model.load_state_dict(checkpoint['state_dict']) # , strict=False\n",
    "model.to(device)\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "print(f'load pretrained model: {pretrained_model_pth}')\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAd56lt4kDxc"
   },
   "source": [
    "And now let's train the model for 10 epochs, evaluating at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "at-h4OWK0aoc",
    "outputId": "7551dc2a-175a-461d-bbbd-2474f43af712",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's train it for 10 epochs\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "num_epochs = 1000 #1000\n",
    "\n",
    "best_iou_metric_sum = -1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    coco_evaluator = evaluate(model, eval_data_loader, device=device)\n",
    "\n",
    "    print('cur_iou_metric', coco_evaluator.coco_eval['segm'].stats)\n",
    "    iou_metrics  = len(coco_evaluator.coco_eval['segm'].stats)\n",
    "    cur_iou_metric_sum = sum(coco_evaluator.coco_eval['segm'].stats)/iou_metrics\n",
    "    print('best_iou_metric_sum:', best_iou_metric_sum)\n",
    "    print('cur_iou_metric_sum:', cur_iou_metric_sum)\n",
    "\n",
    "    if cur_iou_metric_sum > best_iou_metric_sum:\n",
    "        print('model save...')\n",
    "        best_iou_metric_sum = cur_iou_metric_sum\n",
    "        \n",
    "        # torch.save(model.state_dict(), pretrained_model_pth)\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'lr_scheduler_state_dict': lr_scheduler.state_dict(),    # HERE IS THE CHANGE\n",
    "                    }, pretrained_model_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdcpegIsJZoF",
    "outputId": "79ab1e37-5d56-4b4d-a8a2-e92782eb301b"
   },
   "outputs": [],
   "source": [
    "coco_evaluator.coco_eval['segm'].stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA6xKI2tIxY5"
   },
   "outputs": [],
   "source": [
    "step = optimizer.state[optimizer.param_groups[0][\"params\"][-1]][\"step\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = '1001152328_20150714'\n",
    "dataset_path = os.path.join('ToothDataset/test/', test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show origin mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show origin mask\n",
    "mask_path = f'ToothDataset/cbcts/test/label/{test_id}.nii.gz'\n",
    "\n",
    "msks = sitk.ReadImage(mask_path) # h, w, c (y, x, z)\n",
    "msks = sitk.GetArrayFromImage(msks).astype(np.uint8)\n",
    "\n",
    "print(f'ori mask lbl = {np.unique(msks)}, \\nlen = {len(np.unique(msks))}')\n",
    "\n",
    "msk = msks[116,:,:]\n",
    "plt.imshow(msk)\n",
    "\n",
    "print(f'\\nthis mask lbl = {np.unique(msk)}, \\nlen = {len(np.unique(msk))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing one data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmN602iKsuey"
   },
   "source": [
    "Printing the prediction shows that we have a list of dictionaries. Each element of the list corresponds to a different image. As we have a single image, there is a single dictionary in the list.\n",
    "The dictionary contains the predictions for the image we passed. In this case, we can see that it contains `boxes`, `labels`, `masks` and `scores` as fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M58J3O9OtT1G"
   },
   "source": [
    "And let's now visualize the top predicted segmentation mask. The masks are predicted as `[N, 1, H, W]`, where `N` is the number of predictions, and are probability maps between 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = PennFudanDataset(dataset_path)\n",
    "test_img, test_info = test_dataset[0]\n",
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick one image from the test set\n",
    "test_dataset = PennFudanDataset(dataset_path, get_transform(train=False))\n",
    "test_img, test_info = test_dataset[150]\n",
    "test_img_numpy = test_img.mul(255).permute(1, 2, 0).byte().numpy()\n",
    "\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([test_img.to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pred mask: {prediction[0]['masks'].shape}\")\n",
    "print(f\"pred mask score: {prediction[0]['scores']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwT21rzotFbH"
   },
   "source": [
    "Let's inspect the image and the predicted segmentation masks.\n",
    "\n",
    "For that, we need to convert the image, which has been rescaled to 0-1 and had the channels flipped so that we have it in `[C, H, W]` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(test_img.mul(255).permute(1, 2, 0).byte().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(prediction[0]['masks'][0, 0].mul(255).byte().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### concatenate all pred_mask to nii.gz\n",
    "\n",
    "Get Sematic Segmentation Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# concatenate all pred_mask to nii.gz\n",
    "\n",
    "def get_sematic_res(test_id):\n",
    "    # test_id = '1001162439_20150708'\n",
    "    test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "    print('get sematic, file path :', test_path)\n",
    "    \n",
    "    test_dataset = PennFudanDataset(test_path, get_transform(train=False))\n",
    "\n",
    "    slice_num = len(test_dataset)\n",
    "    print('slice_num :', slice_num)\n",
    "\n",
    "    pred_cbct = None\n",
    "    for slice_idx in tqdm(range(slice_num)):\n",
    "        test_img, test_info = test_dataset[slice_idx]\n",
    "\n",
    "        # put the model in evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = model([test_img.to(device)])\n",
    "\n",
    "        pred_score = prediction[0]['scores'].cpu().numpy()\n",
    "        pred_mask = prediction[0]['masks'].cpu().numpy()\n",
    "        pred_mask_num = pred_mask.shape[0]\n",
    "        # print('pred_masks shape :', pred_mask.shape)\n",
    "        # print('pred_scores :', pred_score)\n",
    "        # print('')\n",
    "\n",
    "        new_mask = np.zeros((pred_mask.shape[-2], pred_mask.shape[-1]))\n",
    "\n",
    "        for mask_idx in range(pred_mask_num):\n",
    "            if pred_score[mask_idx] > 0.8:\n",
    "                new_mask = new_mask + pred_mask[mask_idx, 0, :, :]\n",
    "\n",
    "        # thresholding\n",
    "        thresholding_val = 0.6\n",
    "        new_mask[new_mask < thresholding_val] = 0\n",
    "        new_mask[new_mask >= thresholding_val] = 1    \n",
    "        # print(np.unique(new_mask))\n",
    "\n",
    "        new_mask = new_mask[np.newaxis] \n",
    "\n",
    "        if np.any(pred_cbct==None):\n",
    "            pred_cbct = new_mask\n",
    "        else:\n",
    "            pred_cbct = np.concatenate((pred_cbct, new_mask), axis=0)\n",
    "\n",
    "    pred_cbct = pred_cbct.astype('uint8')\n",
    "    print('pred_cbct :', pred_cbct.shape)\n",
    "\n",
    "    # out = sitk.GetImageFromArray(pred_cbct)\n",
    "    # out_name = '{}/pred_sematic_{}.nii.gz'.format(test_path, test_id)\n",
    "    # sitk.WriteImage(out, out_name)\n",
    "    # print('! save ', out_name)\n",
    "    \n",
    "    return pred_cbct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all pred_mask to nii.gz\n",
    "\n",
    "def get_sematic_edge_res(test_id):\n",
    "    # test_id = '1001162439_20150708'\n",
    "    test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "    print('get sematic, file path :', test_path)\n",
    "    \n",
    "    test_dataset = PennFudanDataset(test_path, get_transform(train=False))\n",
    "\n",
    "    slice_num = len(test_dataset)\n",
    "    print('slice_num :', slice_num)\n",
    "\n",
    "    pred_cbct = None\n",
    "    for slice_idx in tqdm(range(slice_num)):\n",
    "        test_img, test_info = test_dataset[slice_idx]\n",
    "\n",
    "        # put the model in evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            prediction = model([test_img.to(device)])\n",
    "\n",
    "        pred_score = prediction[0]['scores'].cpu().numpy()\n",
    "        pred_mask = prediction[0]['masks'].cpu().numpy()\n",
    "        pred_mask_num = pred_mask.shape[0]\n",
    "        # print('pred_masks shape :', pred_mask.shape)\n",
    "        # print('pred_scores :', pred_score)\n",
    "        # print('')\n",
    "\n",
    "        new_mask = np.zeros((pred_mask.shape[-2], pred_mask.shape[-1]))\n",
    "\n",
    "        for mask_idx in range(pred_mask_num):\n",
    "            if pred_score[mask_idx] > 0.8:\n",
    "                new_mask = new_mask + pred_mask[mask_idx, 0, :, :]\n",
    "\n",
    "        # thresholding\n",
    "        thresholding_val = 0.1\n",
    "        new_mask[new_mask < thresholding_val] = 0\n",
    "        new_mask[new_mask >= thresholding_val] = 1    \n",
    "        # print(np.unique(new_mask))\n",
    "\n",
    "        new_mask = new_mask[np.newaxis] \n",
    "\n",
    "        if np.any(pred_cbct==None):\n",
    "            pred_cbct = new_mask\n",
    "        else:\n",
    "            pred_cbct = np.concatenate((pred_cbct, new_mask), axis=0)\n",
    "\n",
    "    pred_cbct = pred_cbct.astype('uint8')\n",
    "    print('pred_cbct :', pred_cbct.shape)\n",
    "\n",
    "    # out = sitk.GetImageFromArray(pred_cbct)\n",
    "    # out_name = '{}/pred_sematic_{}.nii.gz'.format(test_path, test_id)\n",
    "    # sitk.WriteImage(out, out_name)\n",
    "    # print('! save ', out_name)\n",
    "    \n",
    "    return pred_cbct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Instance Segmentation Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_preprocessing(test_id):\n",
    "    # preprocessing\n",
    "    # only remain mask with pred_mask score > 0.8\n",
    "    # make pixel values > 0.6 become 1\n",
    "    \n",
    "    # test_id = '1001162439_20150708'    \n",
    "    test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "\n",
    "    print('Instance preprocessing...')\n",
    "    print('Only remain mask with pred_mask score > 0.8 and make pixel values > 0.6 become 1.\\n')\n",
    "    \n",
    "    test_dataset = PennFudanDataset(test_path, get_transform(train=False))\n",
    "\n",
    "    slice_num = len(test_dataset)\n",
    "    print('slice_num :', slice_num)\n",
    "\n",
    "    new_slices = []\n",
    "\n",
    "    for slice_idx in tqdm(range(slice_num)):\n",
    "        img, info = test_dataset[slice_idx]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = model([img.to(device)])\n",
    "\n",
    "        pred_score = pred[0]['scores'].cpu().numpy()\n",
    "        pred_mask = pred[0]['masks'].cpu().numpy()\n",
    "        pred_mask_num = pred_mask.shape[0]\n",
    "\n",
    "        # only remain mask with pred_mask score > 0.8\n",
    "        new_masks = None\n",
    "        for mask_idx in range(pred_mask_num):\n",
    "            new_mask = pred_mask[mask_idx, 0, :, :]\n",
    "\n",
    "            if pred_score[mask_idx] >= 0.9:\n",
    "                # make pixel values <= 0.5 ecome 0\n",
    "                new_mask[new_mask <= 0.6] = 0\n",
    "                new_mask[new_mask > 0.6] = 1\n",
    "                new_mask = new_mask[np.newaxis]\n",
    "\n",
    "                if np.all(new_masks == None):\n",
    "                    new_masks = new_mask\n",
    "                else:\n",
    "                    new_masks = np.concatenate((new_masks, new_mask), axis=0)\n",
    "\n",
    "        # if no pred_mask score > 0.8 or no mask \n",
    "        if np.all(new_masks == None):\n",
    "            new_masks = np.zeros((pred_mask.shape[-2], pred_mask.shape[-1]))[np.newaxis]\n",
    "\n",
    "        new_slices.append(new_masks)\n",
    "\n",
    "    print(f'len(new_slices) = {len(new_slices)}')\n",
    "    \n",
    "    return new_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_label(new_slices, test_id):\n",
    "    slice_num = len(new_slices)\n",
    "    print('set_new_label...')\n",
    "    print(f'for loop num = slice_num -1 ({slice_num-1})')\n",
    "    \n",
    "    test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "    \n",
    "    out_res = None\n",
    "    pre_slice02 = None\n",
    "    max_lbl = 1 # start with 1 (max_lbl + 1)\n",
    "    had_lbl = False\n",
    "    min_iou = 999\n",
    "\n",
    "                          #range(120,123)\n",
    "    for slice_idx in tqdm(range(slice_num-1)):\n",
    "        # print(f'slice_idx = {slice_idx}')\n",
    "\n",
    "        if np.all(pre_slice02 == None):\n",
    "            slice01 = new_slices[slice_idx].astype('uint8')\n",
    "            slice02 = new_slices[slice_idx+1].astype('uint8')\n",
    "            pre_slice02 = slice02\n",
    "        else:\n",
    "            slice01 = pre_slice02\n",
    "            slice02 = new_slices[slice_idx+1].astype('uint8')\n",
    "            pre_slice02 = slice02\n",
    "\n",
    "        # print(np.unique(slice01))\n",
    "        # print(np.unique(slice02))\n",
    "\n",
    "        # print(slice01.shape)\n",
    "        # print(slice02.shape)\n",
    "        mask01_num = slice01.shape[0]\n",
    "        mask02_num = slice02.shape[0]\n",
    "\n",
    "        res = np.zeros((slice01.shape[-2], slice01.shape[-1]))\n",
    "        # assert -1>0\n",
    "\n",
    "        for m01_idx in range(mask01_num):\n",
    "            mask01 = slice01[m01_idx, :, :]\n",
    "\n",
    "            # mask had label\n",
    "            mask01_max_lbl = np.max(mask01)\n",
    "\n",
    "            if mask01_max_lbl == 1:\n",
    "                had_lbl = False\n",
    "            elif mask01_max_lbl > 1:\n",
    "                had_lbl = True\n",
    "            else:\n",
    "                # all black(0)\n",
    "                break\n",
    "\n",
    "            find = False\n",
    "\n",
    "            for m02_idx in range(mask02_num):\n",
    "                mask02 = slice02[m02_idx, :, :] \n",
    "\n",
    "                # get iou\n",
    "                intersection = mask01 * mask02\n",
    "                intersection[intersection>1] = 1\n",
    "                intersection = np.sum(intersection)      \n",
    "                union = mask01 + mask02\n",
    "                union[union>1] = 1\n",
    "                union = np.sum(union)\n",
    "                iou = intersection/union\n",
    "\n",
    "                if iou < min_iou:\n",
    "                    min_iou = iou\n",
    "\n",
    "                if iou >= 0.3:\n",
    "                    find = True\n",
    "\n",
    "                    if not had_lbl:\n",
    "                        color_lbl = max_lbl + 1\n",
    "                        max_lbl = color_lbl # update\n",
    "                        res[mask01==1] = color_lbl\n",
    "                        mask02[mask02==1] = color_lbl\n",
    "                    else:\n",
    "                        color_lbl = mask01_max_lbl\n",
    "                        res[mask01==mask01_max_lbl] = color_lbl\n",
    "                        mask02[mask02==1] = color_lbl\n",
    "\n",
    "                    # print(f'mask01 idx:{m01_idx} paired with mask02 idx:{m02_idx}, iou: {iou}')\n",
    "                    # print(f'mask01 max val: {np.max(mask01)}, color label: {np.max(mask02)}\\n')\n",
    "\n",
    "                    # plt.subplot(1,3,1)\n",
    "                    # plt.imshow(mask01)\n",
    "                    # plt.subplot(1,3,2)\n",
    "                    # plt.imshow(mask02)\n",
    "\n",
    "            if not find:\n",
    "                if not had_lbl:\n",
    "                    color_lbl = max_lbl + 1\n",
    "                    max_lbl = color_lbl # update\n",
    "\n",
    "                    res[mask01==1] = color_lbl\n",
    "                    # print(f'add new color_lbl = {color_lbl}')\n",
    "                else:\n",
    "                    color_lbl = mask01_max_lbl\n",
    "                    res[mask01==mask01_max_lbl] = color_lbl   \n",
    "\n",
    "        # print('max_lbl = ', max_lbl)\n",
    "        # print('')\n",
    "\n",
    "        res = res[np.newaxis]\n",
    "        if np.all(out_res == None):\n",
    "            out_res = res\n",
    "        else:\n",
    "            out_res = np.concatenate((out_res, res), axis=0)\n",
    "\n",
    "    print(f'min_iou = {min_iou}')        \n",
    "    print(f'out_res.shape = {out_res.shape}')\n",
    "    print(f'np.unique(out_res): {np.unique(out_res)}')\n",
    "    \n",
    "    out = sitk.GetImageFromArray(out_res)\n",
    "    out_name = '{}/pred_instance_{}.nii.gz'.format(test_path, test_id)\n",
    "    sitk.WriteImage(out, out_name)\n",
    "    print('! save ', out_name)\n",
    "\n",
    "    return out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_res(test_id):\n",
    "    test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "    print(f'file path : {test_path}')\n",
    "    \n",
    "    new_slices = instance_preprocessing(test_id)\n",
    "    out_res = set_new_label(new_slices, test_id)\n",
    "    \n",
    "    return out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('ToothDataset/test/')\n",
    "test_name = list(sorted([_ for _ in os.listdir(test_path) if not _.endswith('.ipynb_checkpoints')]))\n",
    "test_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">get sematic result</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbct = get_sematic_res(test_id)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(pred_cbct[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.imshow(pred_cbct[150,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_edge = get_sematic_edge_res(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.imshow(pred_edge[110,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">get instance res</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_res = get_instance_res('1001162439_20150708')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_res = get_instance_res('1001162439_20140520')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3,dpi = 800)\n",
    "\n",
    "slice_idx = 120\n",
    "for i, ax in enumerate(axes.flat, start=1):\n",
    "    m = my_res[slice_idx+i,:,:]\n",
    "    uni_m = np.unique(m)\n",
    "    print(f'unique = {len(uni_m)}')\n",
    "    print(uni_m)\n",
    "    ax.set_title('Test Axes {}'.format(i), size = 5)\n",
    "    ax.imshow(m)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dice Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('ToothDataset/test/')\n",
    "test_name = list(sorted([_ for _ in os.listdir(test_path) if not _.endswith('.ipynb_checkpoints')]))\n",
    "test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cbct = get_sematic_res('1001152328_20150sl714')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get origin mask\n",
    "ori_mask_path = os.path.join('ToothDataset/test/', test_id, 'GrayMasks')\n",
    "\n",
    "slices_path = list([_ for _ in os.listdir(ori_mask_path) if _.endswith('.png')])\n",
    "slices_path = sorted(slices_path, key=lambda s:nfs.get_nums(s))\n",
    "print(len(slices_path))\n",
    "ori_masks = None\n",
    "for p in tqdm(slices_path):\n",
    "    ori_mask = Image.open(os.path.join(ori_mask_path, p))        \n",
    "    ori_mask = np.array(ori_mask)\n",
    "    ori_mask[ori_mask>0] = 1   \n",
    "    ori_mask = ori_mask[np.newaxis]\n",
    "    \n",
    "    if np.any(ori_masks==None):\n",
    "        ori_masks = ori_mask\n",
    "    else:\n",
    "        ori_masks = np.concatenate((ori_masks, ori_mask), axis=0)\n",
    "        \n",
    "print(ori_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ori_masks[100,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_cbct[100,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EdgeMaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get origin edge maps\n",
    "ori_mask_path = os.path.join('ToothDataset/test/', test_id, 'EdgeMaps')\n",
    "\n",
    "slices_path = list([_ for _ in os.listdir(ori_mask_path) if _.endswith('.png')])\n",
    "slices_path = sorted(slices_path, key=lambda s:nfs.get_nums(s))\n",
    "print(len(slices_path))\n",
    "ori_masks = None\n",
    "for p in tqdm(slices_path):\n",
    "    ori_mask = Image.open(os.path.join(ori_mask_path, p))        \n",
    "    ori_mask = np.array(ori_mask)\n",
    "    ori_mask[ori_mask>0] = 1   \n",
    "    ori_mask = ori_mask[np.newaxis]\n",
    "    \n",
    "    if np.any(ori_masks==None):\n",
    "        ori_masks = ori_mask\n",
    "    else:\n",
    "        ori_masks = np.concatenate((ori_masks, ori_mask), axis=0)\n",
    "        \n",
    "print(ori_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ori_masks[100,:,:], cmap='gray')\n",
    "print(np.unique(ori_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_edge[100,:,:], cmap='gray')\n",
    "print(np.unique(pred_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_average_sets(y_true, y_pred):\n",
    "    assert y_true.shape[0]==y_pred.shape[0], \"you should use same size data\"\n",
    "    dice = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        dice.append(dice_coef(y_true[i], y_pred[i]))\n",
    "    print(np.mean(dice))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = dice_average_sets(ori_masks, pred_cbct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = dice_average_sets(ori_masks, pred_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXp9146VIWYu"
   },
   "source": [
    "Show pred masks and boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bxLVP-6OfQc"
   },
   "outputs": [],
   "source": [
    "def write_pred_label_mask(image, label, pred, file_name):\n",
    "    '''\n",
    "    output red color is predict mask,\n",
    "    green color is gt mask,\n",
    "    yellow color is the intersection of prediction mask and gt mask\n",
    "    '''\n",
    "    image = np.array(image)\n",
    "    image = Image.fromarray(image).convert('L')\n",
    "    pred = np.array(pred)\n",
    "    pred[pred<240] = 0 # thresholding, can avoid black border\n",
    "\n",
    "    label = np.array(label)\n",
    "    # image = image.astype(np.uint8)\n",
    "\n",
    "    pred = pred / 255.\n",
    "    label = label / 255.\n",
    "    \n",
    "    pred_mask = (image * pred).astype(np.uint8)   \n",
    "    label_mask = (image * label).astype(np.uint8)\n",
    "    union_mask = (image * np.logical_or(pred_mask, label_mask)).astype(np.uint8)\n",
    "    no_mask = image - union_mask\n",
    "\n",
    "    r = no_mask + label_mask\n",
    "    g = no_mask + pred_mask\n",
    "    b = no_mask\n",
    "\n",
    "    rgb_img = np.stack([r, g, b], -1)\n",
    "    rgb_img = Image.fromarray(rgb_img)\n",
    "\n",
    "    return rgb_img\n",
    "    # rgb_img.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTBnfaECaM9Y"
   },
   "outputs": [],
   "source": [
    "# def check_intersection(ans, pred):\n",
    "#   inter = False\n",
    "\n",
    "#   ans0_sum = np.sum(ans==0)\n",
    "#   pred0_sum = np.sum(pred==0)\n",
    "#   diff = pred - ans\n",
    "#   diff0_sum = np.sum(diff==0)\n",
    "#   print(ans0_sum, pred0_sum, diff0_sum)\n",
    "#   if diff0_sum > pred0_sum:\n",
    "#     inter = True\n",
    "#     print(True)\n",
    "#   return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9vPAajV3hfq"
   },
   "outputs": [],
   "source": [
    "def show_pred_img(img, ans_mask, ans_boxes, pred_mask, pred_boxes): \n",
    "    ans_mask_num = ans_mask.shape[0]\n",
    "    pred_mask_num = pred_mask.shape[0]\n",
    "\n",
    "    ans_line_im = drawLine(img, ans_boxes)\n",
    "    pred_line_im = drawLine(img, pred_boxes)\n",
    "\n",
    "    plt.figure('test', (30, 20), dpi=200)\n",
    "\n",
    "    #----------------------------------------------------------------------------\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.title(\"image\")\n",
    "    plt.imshow(test_img_numpy, cmap='gray')\n",
    "\n",
    "    #----------------------------------------------------------------------------\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.title(\"image & label\\n masks =\" + str(ans_mask_num))\n",
    "    plt.imshow(test_img_numpy, cmap='gray')\n",
    "    # plt.imshow(ans_line_im, cmap='gray')\n",
    "    for i in range(ans_mask_num):\n",
    "        mask = ans_mask[i].mul(255).byte().cpu().numpy()\n",
    "        mask = np.where(mask != 0, i + 1, mask)\n",
    "        lbl_mask = np.ma.masked_where(mask == 0, mask)\n",
    "        plt.imshow(lbl_mask, alpha=1.0, vmin = 1, vmax = ans_mask_num)\n",
    "\n",
    "  #----------------------------------------------------------------------------\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.title(\"pred image & label\\n masks =\" + str(pred_mask_num))\n",
    "    plt.imshow(test_img_numpy, cmap='gray')\n",
    "    # plt.imshow(pred_line_im, cmap='gray')\n",
    "\n",
    "    for i in range(pred_mask_num):\n",
    "        mask = pred_mask[i, 0].mul(255).byte().cpu().numpy()\n",
    "        mask = np.where(mask != 0, i + 1, mask)\n",
    "        lbl_mask = np.ma.masked_where(mask == 0, mask)\n",
    "        plt.imshow(lbl_mask, alpha=1.0, vmin = 1, vmax = pred_mask_num)\n",
    "\n",
    "  #----------------------------------------------------------------------------\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.title(\"label & pred image\\n\")\n",
    "    # plt.imshow(pred_line_im, cmap='gray')\n",
    "\n",
    "    # (0, 11), (3, 1),\n",
    "    ans_mask = ans_mask[3].mul(255).byte().cpu().numpy()\n",
    "    pred_mask = pred_mask[1, 0].mul(255).byte().cpu().numpy()\n",
    "\n",
    "    rgb_img = write_pred_label_mask(test_img_numpy, ans_mask, pred_mask, 'test') \n",
    "    plt.imshow(rgb_img)\n",
    "\n",
    "    # plt.savefig('pred.png', dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "C_Q0bgt2Jmfv",
    "outputId": "57baf646-35cf-46c7-8e27-0290b299c263"
   },
   "outputs": [],
   "source": [
    "img = Image.fromarray(test_img_numpy)\n",
    "ans_boxes = test_info['boxes']\n",
    "ans_mask = test_info['masks']\n",
    "pred_boxes = prediction[0]['boxes']\n",
    "pred_mask = prediction[0]['masks']\n",
    "\n",
    "show_pred_img(img, ans_mask, ans_boxes, pred_mask, pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "H-C5vppDe2q3",
    "outputId": "f2610a77-02b0-4875-ba36-a81900ab5698"
   },
   "outputs": [],
   "source": [
    "# def show_intersec_img(img, ans_mask, ans_boxes, pred_mask, pred_boxes): \n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "ans_mask_num = ans_mask.shape[0]\n",
    "pred_mask_num = pred_mask.shape[0]\n",
    "\n",
    "ans_line_im = drawLine(img, ans_boxes)\n",
    "pred_line_im = drawLine(img, pred_boxes)\n",
    "\n",
    "# (0, 11), (3, 1)\n",
    "mask = ans_mask[13].mul(255).byte().cpu().numpy()      \n",
    "mask02 = pred_mask[12, 0].mul(255).byte().cpu().numpy()\n",
    "rgb_img = write_pred_label_mask(test_img_numpy, mask, mask02, 'test')\n",
    "plt.imshow(rgb_img)\n",
    "\n",
    "# return rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "U2NN6grNHtY4",
    "outputId": "8a481c39-a631-4c36-88f2-b565dfeca010"
   },
   "outputs": [],
   "source": [
    "img = Image.fromarray(test_img_numpy)\n",
    "ans_boxes = test_info['boxes']\n",
    "ans_mask = test_info['masks']\n",
    "pred_boxes = prediction[0]['boxes']\n",
    "pred_mask = prediction[0]['masks']\n",
    "\n",
    "show_pred_img(img, ans_mask, ans_boxes, pred_mask, pred_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('coins.jpg')\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "print(np.unique(thresh))\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "# plt.imshow(opening, cmap='gray')\n",
    "# sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening,cv.DIST_L2,5)\n",
    "ret, sure_fg = cv.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=180)\n",
    "plt.rcParams['axes.titlesize'] = 5\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.title('origin')\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('opening')\n",
    "plt.axis('off')\n",
    "plt.imshow(opening, cmap='gray')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.title('sure_fg')\n",
    "plt.axis('off')\n",
    "plt.imshow(sure_fg, cmap='gray')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.title('sure_bg')\n",
    "plt.axis('off')\n",
    "plt.imshow(sure_bg, cmap='gray')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.title('unknown')\n",
    "plt.axis('off')\n",
    "plt.imshow(unknown, cmap='gray')\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.title('dist_transform')\n",
    "plt.axis('off')\n",
    "plt.imshow(dist_transform, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "plt.imshow(markers, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('markers')\n",
    "plt.imshow(markers, cmap='gray')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('img')\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D tooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = new_slices.copy()\n",
    "img = img[110,:,:]\n",
    "img[img>0] = 255\n",
    "thresh = img\n",
    "# ret, thresh = cv.threshold(img,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "\n",
    "img = cv.cvtColor(img,cv.COLOR_GRAY2BGR)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "print(np.unique(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "skeleton = skeletonize(img)\n",
    "\n",
    "plt.figure(dpi=180)\n",
    "plt.imshow(skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv.morphologyEx(thresh,cv.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 3)\n",
    "ret, sure_fg = cv.threshold(dist_transform, 0.2*dist_transform.max(), 255, 0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=180)\n",
    "plt.rcParams['axes.titlesize'] = 5\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.title('origin')\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('opening')\n",
    "plt.axis('off')\n",
    "plt.imshow(opening, cmap='gray')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.title('sure_fg')\n",
    "plt.axis('off')\n",
    "plt.imshow(sure_fg, cmap='gray')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.title('sure_bg')\n",
    "plt.axis('off')\n",
    "plt.imshow(sure_bg, cmap='gray')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.title('unknown')\n",
    "plt.axis('off')\n",
    "plt.imshow(unknown, cmap='gray')\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.title('dist_transform')\n",
    "plt.axis('off')\n",
    "plt.imshow(dist_transform, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "print(np.unique(markers))\n",
    "plt.imshow(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = cv.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img = new_slices.copy()\n",
    "_markers = markers.copy()\n",
    "plt.figure(dpi=180)\n",
    "plt.rcParams['axes.titlesize'] = 5\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.title('origin')\n",
    "plt.imshow(ori_img[110,:,:], cmap='gray')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('markers')\n",
    "_markers[_markers==1] = 0\n",
    "plt.imshow(_markers)\n",
    "print(np.unique(_markers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, markers = cv.connectedComponents(thresh)\n",
    "print(np.unique(markers))\n",
    "plt.imshow(markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D tooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "watershed get instance result<br>\n",
    "1. get sematic res\n",
    "2. use watershed algo get label\n",
    "3. reset label get cbct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label, binary_dilation, binary_opening, binary_closing, binary_erosion, distance_transform_edt\n",
    "# from scipy.stats import threshold\n",
    "from scipy import stats\n",
    "from skimage.segmentation import watershed\n",
    "# from skimage.morphology import binary_dilation, binary_opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "A = np.array(\n",
    "  [\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0],\n",
    "  ]\n",
    ")\n",
    "\n",
    "dis = ndimage.morphology.distance_transform_edt(A)\n",
    "print(dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_slices = get_sematic_res(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_slices[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = binary_opening(new_slices,iterations=3)\n",
    "sure_bg = binary_dilation(opening, iterations=3)\n",
    "sure_bg = np.uint8(sure_bg)\n",
    "\n",
    "distance_transform = distance_transform_edt(opening)\n",
    "\n",
    "ret, sure_fg = cv.threshold(distance_transform, 0.35 * distance_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "# Label connected components\n",
    "markers, num_markers = label(sure_fg)\n",
    "\n",
    "labels = watershed(-distance_transform, markers, mask=opening)\n",
    "\n",
    "# ---------------------------------------------------------------------------------\n",
    "idx = 110\n",
    "plt.figure(dpi=200)\n",
    "plt.subplot(231)\n",
    "plt.title('opening')\n",
    "plt.imshow(opening[idx,:,:])\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('sure_bg')\n",
    "plt.imshow(sure_bg[idx,:,:])\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.title('sure_fg')\n",
    "plt.imshow(sure_fg[idx,:,:])\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.title('markers')\n",
    "plt.imshow(markers[idx,:,:])\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.title('labels')\n",
    "plt.imshow(labels[idx,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_edge = np.uint8(pred_edge)\n",
    "opening = np.uint8(opening)\n",
    "# opening = cv.subtract(opening, pred_edge)\n",
    "plt.imshow(opening[110,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_transform_edge = distance_transform_edt(pred_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = cv.add(distance_transform, distance_transform_edge)\n",
    "plt.imshow(distance[110,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_transform[110,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(distance_transform[110,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, sure_fg = cv.threshold(distance_transform, 0.35 * distance_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('sure_fg')\n",
    "plt.imshow(sure_fg[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_transform.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # thresholding\n",
    "# val = 0.2 * distance_transform.max()\n",
    "# distance_transform[distance_transform <= val] = 255\n",
    "# distance_transform[distance_transform != 255] = 0\n",
    "# sure_fg = np.uint8(distance_transform)\n",
    "\n",
    "# plt.title('sure_fg')\n",
    "# plt.imshow(sure_fg[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = cv.subtract(sure_bg, sure_fg)\n",
    "\n",
    "plt.title('unknown')\n",
    "plt.imshow(unknown[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label connected components\n",
    "markers, num_markers = label(sure_fg)\n",
    "plt.imshow(markers[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "plt.imshow(markers[150,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed(-distance, markers, mask=opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed(-distance_transform, markers, mask=opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = watershed(-distance_transform, markers, mask=opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[145,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_edge = watershed(pred_edge, markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_slices[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(labels[150,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "plt.subplot(131)\n",
    "plt.imshow(opening[110,:,:])\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(sure_bg[110,:,:])\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(labels[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "out = sitk.GetImageFromArray(labels)\n",
    "out_name = '{}/labels_{}.nii.gz'.format(test_path, test_id)\n",
    "sitk.WriteImage(out, out_name)\n",
    "print('! save ', out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100)\n",
    "plt.imshow(labels[100,:,:])\n",
    "print(np.unique(labels[90,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'ToothDataset/test/1001152328_20150714/1001486953_20180109_02.nii.gz'\n",
    "imgs = sitk.ReadImage(img_path)\n",
    "imgs = sitk.GetArrayFromImage(imgs).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'ToothDataset/test/1001152328_20150714/gt_1001486953_20180109.nii.gz'\n",
    "gt_imgs = sitk.ReadImage(img_path)\n",
    "gt_imgs = sitk.GetArrayFromImage(gt_imgs).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gt_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_imgs[gt_imgs>1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = dice_average_sets(gt_imgs, imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[110,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = imgs[110,:,:]\n",
    "# i = np.float32(i)\n",
    "# ii = cv.GaussianBlur(i,(15, 15), 0)\n",
    "\n",
    "# ii[ii<0.5] = 0\n",
    "# ii[ii>0] = 1\n",
    "# plt.imshow(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = binary_opening(imgs, iterations=3)\n",
    "# opening = binary_erosion(opening, iterations=3)\n",
    "\n",
    "sure_bg = binary_dilation(opening, iterations=3)\n",
    "sure_bg = np.uint8(sure_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_transform = distance_transform_edt(opening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, sure_fg = cv.threshold(distance_transform, 0.3 * distance_transform.max(), 255, 0)\n",
    "sure_fg = np.uint8(sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label connected components\n",
    "markers, num_markers = label(sure_fg)\n",
    "\n",
    "labels = watershed(-distance_transform, markers, mask=imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 120\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.title('opening')\n",
    "plt.imshow(opening[idx,:,:])\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.title('sure_bg')\n",
    "plt.imshow(sure_bg[idx,:,:])\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.title('sure_fg')\n",
    "plt.imshow(sure_fg[idx,:,:])\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.title('distance_transform')\n",
    "plt.imshow(-distance_transform[idx,:,:], cmap='gray')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.title('markers')\n",
    "plt.imshow(markers[idx,:,:])\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.title('labels')\n",
    "plt.imshow(labels[idx,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('ToothDataset/test/', test_id)\n",
    "out = sitk.GetImageFromArray(labels)\n",
    "out_name = '{}/labels_{}.nii.gz'.format(test_path, '1001486953_20180109')\n",
    "sitk.WriteImage(out, out_name)\n",
    "print('! save ', out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[123, :, :]\n",
    "img = np.uint8(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img, (3,3), 0)\n",
    "blur = np.uint8(blur)\n",
    "plt.imshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行霍夫圆变换\n",
    "circles = cv.HoughCircles(img, cv.HOUGH_GRADIENT, 1, 0.5, param1=1, param2=4, minRadius=1, maxRadius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(np.uint8(img))\n",
    "image = im.copy()\n",
    "\n",
    "draw = ImageDraw.Draw(image) #實例化一個對象\n",
    "\n",
    "for circle in circles[0]:\n",
    "    x = int(circle[0])\n",
    "    y = int(circle[1])\n",
    "\n",
    "    # 半径\n",
    "    r = int(circle[2])\n",
    "\n",
    "    # 在原图用指定颜色标记出圆的边界\n",
    "    draw.ellipse((x-r, y-r, x+r, y+r), fill=255, width=1)\n",
    "    \n",
    "    # 画出圆的圆心\n",
    "    # draw.ellipse((x, y, 1, 1), fill=\"blue\")\n",
    "    \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawCircle(im, circles):\n",
    "    im = Image.fromarray(np.uint8(im))\n",
    "    image = im.copy()\n",
    "\n",
    "    draw = ImageDraw.Draw(image) #實例化一個對象\n",
    "\n",
    "    for circle in circles[0]:\n",
    "        x = int(circle[0])\n",
    "        y = int(circle[1])\n",
    "        \n",
    "        # 半径\n",
    "        r = int(circle[2])\n",
    "        \n",
    "        # 在原图用指定颜色标记出圆的边界\n",
    "        draw.circle((x, y), r, (0, 0, 255), 3)\n",
    "        # 画出圆的圆心\n",
    "        draw.circle((x, y),5, (0, 255, 0), -1)\n",
    "        \n",
    "        # draw.line((100,200, 150, 300), fill=128, width=3)\n",
    "        draw.line((xmin, ymin, xmax, ymin), fill=\"red\", width=1)  #line start and end coord, line width\n",
    "        draw.line((xmax, ymin, xmax, ymax), fill=\"red\", width=1)\n",
    "        draw.line((xmax, ymax, xmin, ymax), fill=\"red\", width=1)\n",
    "        draw.line((xmin, ymax, xmin, ymin), fill=\"red\", width=1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for circle in circles[0]:\n",
    "    # 圆的基本信息\n",
    "    # 坐标行列－圆心坐标\n",
    "    x = int(circle[0])\n",
    "    y = int(circle[1])\n",
    "    # 半径\n",
    "    r = int(circle[2])\n",
    "    # 在原图用指定颜色标记出圆的边界\n",
    "    cv.circle(img, (x, y), r, (0, 0, 255), 3)\n",
    "    # 画出圆的圆心\n",
    "    cv.circle(img, (x, y),5, (0, 255, 0), -1)\n",
    "\n",
    "    cv.imshow(\"image\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 读取图像\n",
    "img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 进行高斯模糊\n",
    "blur = cv2.GaussianBlur(img, (9,9), 0)\n",
    "\n",
    "# 进行霍夫圆变换\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, 50, param1=50, param2=30, minRadius=0, maxRadius=0)\n",
    "\n",
    "# 输出圆形的数量和半径\n",
    "print(\"圆形数量:\", len(circles[0]))\n",
    "for i in circles[0,:]:\n",
    "    print(\"圆形半径:\", i[2])\n",
    "\n",
    "# 在图像中标记圆形\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0,:]:\n",
    "        # 画出圆形\n",
    "        cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "        # 画出圆心\n",
    "        cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)\n",
    "\n",
    "# 显示图像\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "TeethSeg",
   "language": "python",
   "name": "teethseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045816cebf604ed1b753a6346d76ba8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0edaade0427d4be48aaf90d21c320f77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0fca824b90ee4c0581aa00cd5494f37f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79e163d7476a4ab0a1ed8cf4ced63bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fca824b90ee4c0581aa00cd5494f37f",
      "placeholder": "​",
      "style": "IPY_MODEL_b1f9df056a0549f1b855975b3a764031",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 275MB/s]"
     }
    },
    "a2be8afdf34b41d4899044bd60a1578a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c70f2759a56943e4afbe9b16e8cb674d",
       "IPY_MODEL_aad68761f4104facab4f5ebcaa5757ec",
       "IPY_MODEL_79e163d7476a4ab0a1ed8cf4ced63bc2"
      ],
      "layout": "IPY_MODEL_fdf4af52c36044efb0856358f20bc9c3"
     }
    },
    "aad68761f4104facab4f5ebcaa5757ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_045816cebf604ed1b753a6346d76ba8a",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0edaade0427d4be48aaf90d21c320f77",
      "value": 102530333
     }
    },
    "b1f9df056a0549f1b855975b3a764031": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c70f2759a56943e4afbe9b16e8cb674d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d950bd6f7ee645738dee16375d152398",
      "placeholder": "​",
      "style": "IPY_MODEL_f5b9743788664542a057cf35ac35118f",
      "value": "100%"
     }
    },
    "d950bd6f7ee645738dee16375d152398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5b9743788664542a057cf35ac35118f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdf4af52c36044efb0856358f20bc9c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
